{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean holding period: 25 days\n"
     ]
    }
   ],
   "source": [
    "instruments = pd.read_csv('../../Average_holdings_2015.csv')\n",
    "mean_holding_period = round(instruments.days.mean())\n",
    "print('mean holding period:', mean_holding_period, 'days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_dict = dict(zip(instruments.Symbol, instruments.days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "start_date = '2013-06-03'\n",
    "end_date = '2015-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of intersection between lists: 52\n"
     ]
    }
   ],
   "source": [
    "raw_data_path = 'raw/'\n",
    "original_path = 'ourpped/'\n",
    "testing_oris_method = 'testing_oris_method/'\n",
    "\n",
    "stocknet_tickers = ['XOM', 'RDS-B', 'PTR', 'CVX', 'TOT', 'BP', 'BHP', 'SNP', 'SLB', 'BBL',\n",
    "                    'AAPL', 'PG', 'BUD', 'KO', 'PM', 'TM', 'PEP', 'UN', 'UL', 'MO',\n",
    "                    'JNJ', 'PFE', 'NVS', 'UNH', 'MRK', 'AMGN', 'MDT', 'ABBV', 'SNY', 'CELG',\n",
    "                    'AMZN', 'BABA', 'WMT', 'CMCSA', 'HD', 'DIS', 'MCD', 'CHTR', 'UPS', 'PCLN',\n",
    "                    'NEE', 'DUK', 'D', 'SO', 'NGG', 'AEP', 'PCG', 'EXC', 'SRE', 'PPL',\n",
    "                    'IEP', 'HRG', 'CODI', 'REX', 'SPLP', 'PICO', 'AGFS', \n",
    "                    'BCH', 'BSAC', 'BRK-A', 'JPM', 'WFC', 'BAC', 'V', 'C', 'HSBC', 'MA',\n",
    "                    'GE', 'MMM', 'BA', 'HON', 'UTX', 'LMT', 'CAT', 'GD', 'DHR', 'ABB',\n",
    "                    'GOOG', 'MSFT', 'FB', 'T', 'CHL', 'ORCL', 'TSM', 'VZ', 'INTC', 'CSCO' ] #'GMRE'\n",
    "\n",
    "print('num of intersection between lists:', len(set(inst_dict.keys()).intersection(stocknet_tickers)))\n",
    "\n",
    "### create dict for mean holdings for stocknet\n",
    "stocknet_tickers_dict = {}\n",
    "for s in stocknet_tickers:\n",
    "    try:\n",
    "        stocknet_tickers_dict[s] = int(Inst_dict[s])\n",
    "    except:\n",
    "        stocknet_tickers_dict[s] = int(mean_holding_period)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_percentege = 100 #adjust according to pecentage on 'ourpped'\n",
    "def up_days(s):    \n",
    "    stock_movement_path = os.path.join(raw_data_path, '{}.csv'.format(s))\n",
    "    df = pd.read_csv(stock_movement_path)\n",
    "    \n",
    "    #append mean holdings per stock\n",
    "    mean_holding = stocknet_tickers_dict[s]\n",
    "\n",
    "    #### Adjusting accordingly to the stocknet ####\n",
    "\n",
    "    # vector that normalize the prices by adjusted_price(t-1)\n",
    "    norm_vector = pd.Series(df['Adj Close']).shift(1).fillna(method ='bfill') #fill the first value with the second\n",
    "\n",
    "#     # norm by close at t\n",
    "#     col_adj = ['Open', 'High', 'Low', 'Volume']\n",
    "#     for col in col_adj:\n",
    "#         stock_sample[col] = stock_sample[col]/stock_sample['Close'] -1\n",
    "\n",
    "    ## add my own features ##\n",
    "    #1) avergae mean per each stock\n",
    "    df.loc[:,'average_mean'] = df.loc[:,'Adj Close'].rolling(mean_holding).mean()\n",
    "    df.loc[:,'average_mean'] = mult_percentege*(df.loc[:,'average_mean']/df.loc[:,'Adj Close'] -1) #adjust according to paper\n",
    "    \n",
    "    #norm by 'close' at t-1\n",
    "    col_adj_t_minus_1 = ['Close', 'Adj Close']\n",
    "    for col in col_adj_t_minus_1:\n",
    "        df[col] = df[col]/norm_vector -1\n",
    "    \n",
    "    #2) up most of the days\n",
    "    df.loc[:,'up_days_mean']=\\\n",
    "    df.loc[:,'Adj Close'].rolling(mean_holding).agg(lambda x: (x > 0).mean())\n",
    "    df.loc[:,'up_days_mean'] = MinMaxScaler().fit_transform(df.loc[:,'up_days_mean'].values.reshape(-1, 1))\n",
    "    \n",
    "    #mask between dates\n",
    "    mask = (df['Date'] >= start_date) & (df['Date'] <= end_date)\n",
    "    df = df.loc[mask]\n",
    "    \n",
    "    return  np.vstack([df['average_mean'].values, df['up_days_mean'].values]).T  #df['up_days_mean'].values, df['average_mean'].values #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert new column to the orig df\n",
    "def change_orig_df(s, num_row=0):\n",
    "    #original df\n",
    "    df_orig = pd.read_csv(os.path.join(original_path,'{}.csv'.format(s)),header=None)\n",
    "    df_new = df_orig.copy()\n",
    "\n",
    "    #insert new variable - up days\n",
    "    if num_row == 0:\n",
    "        tmp_last_columns = df_new.iloc[:,-2:].copy()\n",
    "        df_new.iloc[:,-2:]  = up_days(s)   # was  [:, -3], [:,-4:-2]\n",
    "        df_new = pd.concat([df_new, pd.DataFrame(tmp_last_columns)], axis=1)\n",
    "    else:\n",
    "        tmp_last_columns = df_new.iloc[-num_row:,-2:].copy()\n",
    "        df_new.iloc[-num_row:,-2:]  = up_days(s)[-num_row:]\n",
    "        df_new = pd.concat([df_new, pd.DataFrame(tmp_last_columns)], axis=1)\n",
    "        \n",
    "        #df_new.iloc[-num_row:, -3] = up_days(s)[-num_row:]      # was [:,-3], up_days(s)[-num_row:]  df_new.iloc[-num_row:, -4:-2]\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "except: PTR\n",
      "except: TOT\n",
      "except: SNP\n",
      "except: SLB\n",
      "except: BBL\n",
      "except: UN\n",
      "except: UL\n",
      "except: NVS\n",
      "except: SNY\n",
      "except: BABA\n",
      "except: PCLN\n",
      "except: NGG\n",
      "except: HRG\n",
      "except: CODI\n",
      "except: REX\n",
      "except: SPLP\n",
      "except: PICO\n",
      "except: AGFS\n",
      "except: BRK-A\n",
      "except: ABB\n",
      "except: TSM\n"
     ]
    }
   ],
   "source": [
    "for s in stocknet_tickers:\n",
    "    try:\n",
    "        df_new = change_orig_df(s).round(6)\n",
    "        df_new.to_csv(os.path.join(testing_oris_method,'{}_testing_avgholdings2015.csv'.format(s)),header=None, index=None)\n",
    "    except:\n",
    "        print('except:', s)\n",
    "\n",
    "\n",
    "# df_new = change_orig_df(s).round(6)\n",
    "# df_new.to_csv(os.path.join(testing_oris_method,'{}_testing_avgholdings2015.csv'.format(s)),header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement for all stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = 'raw/'\n",
    "original_path = 'ourpped/'\n",
    "s1 = 'AAPL'\n",
    "s2 = 'AMZN'\n",
    "stock_path = os.path.join(raw_data_path, '{}.csv'.format(s1))\n",
    "stock_sample = pd.read_csv(stock_path)\n",
    "\n",
    "meanholding_tmp = int(inst_dict[s1])\n",
    "stock_sample.loc[:, 'average_mean'] = stock_sample.loc[:, 'Adj Close'].rolling(meanholding_tmp).mean()\n",
    "#norm by adj close\n",
    "mult_percentage = 100\n",
    "stock_sample.loc[:, 'average_mean'] = mult_percentage*(stock_sample.loc[:, 'average_mean']/\n",
    "                                                       stock_sample.loc[:, 'Adj Close'] - 1)\n",
    "\n",
    "# adjusting accordingly to the txt #\n",
    "# norm by close at t\n",
    "norm_vector = pd.Series(stock_sample['Adj Close']).shift(1).fillna(method='bfill')\n",
    "col_adj = ['Open', 'High', 'Low', 'Volume']\n",
    "for col in col_adj:\n",
    "    stock_sample[col] = stock_sample[col]/stock_sample['Close'] - 1\n",
    "    \n",
    "# norm by close at t-1\n",
    "col_adj_t_minus_1 = ['Close', 'Adj Close']\n",
    "for col in col_adj_t_minus_1:\n",
    "    stock_sample[col] = stock_sample[col]/norm_vector - 1\n",
    "    \n",
    "df = stock_sample.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>average_mean</th>\n",
       "      <th>up_days_mean</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>-0.00256</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>-8.527576</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>100899.942989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date      Open      High      Low     Close  Adj Close  \\\n",
       "1257  2017-09-01  0.004572  0.005425 -0.00256  0.000305   0.000305   \n",
       "\n",
       "      average_mean  up_days_mean         Volume  \n",
       "1257     -8.527576      0.782609  100899.942989  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 'up_days_mean'] = df.loc[:, 'Adj Close'].rolling(meanholding_tmp).agg(lambda x: (x>0).mean())\n",
    "#scale\n",
    "df.loc[:, 'up_days_mean'] = MinMaxScaler().fit_transform(df.loc[:, 'up_days_mean'].values.reshape(-1, 1))\n",
    "\n",
    "#change order\n",
    "new_df_order = ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'average_mean', 'up_days_mean', 'Volume']\n",
    "df = df[new_df_order]\n",
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['Date'] >= start_date) & (df['Date'] <= end_date)\n",
    "df = df.loc[mask]\n",
    "df.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path = 'ourpped/'\n",
    "df_orig = pd.read_csv(os.path.join(original_path,'{}.csv'.format(s1)),header=None)\n",
    "df_orig.head()\n",
    "df_new = df_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_new_columns = np.vstack([df['average_mean'].values, df['up_days_mean'].values]).T\n",
    "tmp_last_columns = df_new.iloc[:, -2:].copy()\n",
    "df_new.iloc[:, -2:] = tmp_new_columns\n",
    "df_new = pd.concat([df_new, pd.DataFrame(tmp_last_columns)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002215</td>\n",
       "      <td>0.363858</td>\n",
       "      <td>-1.828186</td>\n",
       "      <td>0.220128</td>\n",
       "      <td>0.220127</td>\n",
       "      <td>-0.673593</td>\n",
       "      <td>-1.276852</td>\n",
       "      <td>-1.713707</td>\n",
       "      <td>-0.949655</td>\n",
       "      <td>-1.295995</td>\n",
       "      <td>-2.789459</td>\n",
       "      <td>-0.580885</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.171677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.870223</td>\n",
       "      <td>1.139527</td>\n",
       "      <td>-0.427319</td>\n",
       "      <td>-0.312838</td>\n",
       "      <td>-0.312846</td>\n",
       "      <td>-0.011565</td>\n",
       "      <td>-0.825038</td>\n",
       "      <td>-1.485826</td>\n",
       "      <td>-0.731958</td>\n",
       "      <td>-0.790216</td>\n",
       "      <td>-2.089251</td>\n",
       "      <td>-0.453149</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.986561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.121322</td>\n",
       "      <td>1.260365</td>\n",
       "      <td>-0.314531</td>\n",
       "      <td>-0.934764</td>\n",
       "      <td>-0.934782</td>\n",
       "      <td>0.939114</td>\n",
       "      <td>0.233220</td>\n",
       "      <td>-0.537524</td>\n",
       "      <td>0.086406</td>\n",
       "      <td>0.193033</td>\n",
       "      <td>-0.853451</td>\n",
       "      <td>0.323316</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58.435165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.598781</td>\n",
       "      <td>1.947728</td>\n",
       "      <td>-1.005795</td>\n",
       "      <td>-1.494014</td>\n",
       "      <td>-1.493998</td>\n",
       "      <td>1.871554</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>1.117097</td>\n",
       "      <td>1.349731</td>\n",
       "      <td>1.731397</td>\n",
       "      <td>0.921408</td>\n",
       "      <td>1.671675</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>57.562145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.201875</td>\n",
       "      <td>0.323667</td>\n",
       "      <td>-2.046127</td>\n",
       "      <td>0.764040</td>\n",
       "      <td>0.764051</td>\n",
       "      <td>0.740579</td>\n",
       "      <td>0.908979</td>\n",
       "      <td>0.459466</td>\n",
       "      <td>0.411936</td>\n",
       "      <td>0.952945</td>\n",
       "      <td>0.428645</td>\n",
       "      <td>0.733115</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.001949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.002215  0.363858 -1.828186  0.220128  0.220127 -0.673593 -1.276852   \n",
       "1  0.870223  1.139527 -0.427319 -0.312838 -0.312846 -0.011565 -0.825038   \n",
       "2  0.121322  1.260365 -0.314531 -0.934764 -0.934782  0.939114  0.233220   \n",
       "3  1.598781  1.947728 -1.005795 -1.494014 -1.493998  1.871554  1.687500   \n",
       "4 -1.201875  0.323667 -2.046127  0.764040  0.764051  0.740579  0.908979   \n",
       "\n",
       "         7         8         9         10        11        12   11         12  \n",
       "0 -1.713707 -0.949655 -1.295995 -2.789459 -0.580885  0.347826  0.0  59.171677  \n",
       "1 -1.485826 -0.731958 -0.790216 -2.089251 -0.453149  0.347826  0.0  58.986561  \n",
       "2 -0.537524  0.086406  0.193033 -0.853451  0.323316  0.347826 -1.0  58.435165  \n",
       "3  1.117097  1.349731  1.731397  0.921408  1.671675  0.347826 -1.0  57.562145  \n",
       "4  0.459466  0.411936  0.952945  0.428645  0.733115  0.347826  1.0  58.001949  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_oris_method = 'testing_oris_method/'\n",
    "df_new.to_csv(os.path.join(testing_oris_method, '{}.csv'.format(s1)), header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Psychological-Adv-ALSTM-Rania",
   "language": "python",
   "name": "psychological-adv-alstm-rania"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
